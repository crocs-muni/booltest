{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import itertools\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from scipy import stats\n",
    "from scipy.misc import derivative\n",
    "\n",
    "# Pval generation related functions, previously in the notebook\n",
    "from booltest.pvals import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def pvalue_comp(fnc, extremes, dx, bin_tup, by_bins=True):\n",
    "    \"\"\"Extremes = [(val, direction +1\\-1)] \"\"\"\n",
    "    nints = len(extremes)\n",
    "    areas = [0] * nints\n",
    "    nbounds = [x[0] for x in extremes]\n",
    "    nbins = [binize(x[0], bin_tup) for x in extremes]\n",
    "    bmin = min(nbounds)\n",
    "    bmax = max(nbounds)\n",
    "    cp = 0\n",
    "    iterc = 0\n",
    "    results = []\n",
    "    print('OK: ', nints, nbins)\n",
    "    \n",
    "    while cp <= 1.0:  # integration step\n",
    "        iterc += 1\n",
    "        if iterc > 10000:\n",
    "            raise ValueError('exc')  # Hard-termination to avoid infinite cycle.\n",
    "        \n",
    "        # Integration by increasing pvalue and tabulating.\n",
    "        # Each area grows at the same pace. pvalue is a sum of areas.\n",
    "        # Termination - bounds are crossing / touching.\n",
    "        \n",
    "        # Integrate each area with one step but in such a way the area is the same. \n",
    "        max_area = max(areas)\n",
    "        min_area = min(areas)\n",
    "        sum_area = sum(areas)\n",
    "        err = max([abs(x) for x in all_diffs(areas)])\n",
    "        areas_str = ['%.7f' % x for x in areas]\n",
    "        #print('Main iter: %s, cp: %.7f, mina: %.7f, maxa: %.7f, suma: %.7f, err: %.7f, a: [%s], n: %s' \n",
    "        #      % (iterc, cp, min_area, max_area, sum_area, err, ', '.join(areas_str), nbins))\n",
    "        \n",
    "        subit = 0\n",
    "        while any([x <= min_area for x in areas]):\n",
    "            subit += 1\n",
    "            #print('.. subit: %s' % subit)\n",
    "            \n",
    "            for ix in range(nints):\n",
    "                if areas[ix] > min_area :\n",
    "                    continue\n",
    "                if by_bins:\n",
    "                    areas[ix] += get_bin_val(nbins[ix], bin_tup)\n",
    "                    nbounds[ix] = get_bin_start(nbins[ix], bin_tup)\n",
    "                    nbins[ix] = move_bound(nbins[ix], 1, extremes[ix][1])\n",
    "                else:\n",
    "                    areas[ix] += fnc(nbounds[ix])\n",
    "                    nbounds[ix] = move_bound(nbounds[ix], dx, extremes[ix][1])        \n",
    "        cp = sum(areas)\n",
    "        \n",
    "        crit_int = [None]*nints\n",
    "        for i in range(nints):\n",
    "            crit_int[i] = (extremes[i][0], nbounds[i]) if extremes[i][1] > 0 else (nbounds[i], extremes[i][0])\n",
    "            \n",
    "        results.append((cp, crit_int, copy.deepcopy(areas), err))\n",
    "        \n",
    "    #print('Main iter: %s, cp: %s, mina: %s, maxa: %s, suma: %s, a: %s' \n",
    "    #          % (iterc, cp, min(areas), max(areas), sum(areas), areas))\n",
    "    #print('Total: %s' % (sum([get_bin_val(ix, bin_tup) for ix in range(len(bin_tup[0]))])))\n",
    "    #print(json.dumps(results, indent=2))\n",
    "    return results\n",
    "\n",
    "\n",
    "def tabulate_pvals(val, nbins=200, abs_val=False, target_pvals=[0.0,0.0001,0.0005,0.001,0.005,0.01]):\n",
    "    inp_iter = val['zscores']\n",
    "    if abs_val:\n",
    "        inp_iter = [abs(x) for x in inp_iter]\n",
    "    \n",
    "    bin_tup = get_bins(inp_iter, nbins=nbins, full=True)\n",
    "    bb = get_distrib_fbins(inp_iter, bin_tup)\n",
    "    \n",
    "    bin_size = bin_tup[1]\n",
    "    minv, maxv = bin_tup[2], bin_tup[3] \n",
    "    bins = np.array([x[0] for x in bb])\n",
    "    \n",
    "    # Tabulate pvalues\n",
    "    # build_integrator(bin_tup)\n",
    "    extremes = [\n",
    "        [minv, 1],\n",
    "        [0, -1],\n",
    "        [0, +1],\n",
    "        [maxv, -1]\n",
    "    ] if not abs_val else [\n",
    "        [minv, 1],\n",
    "        [maxv, -1]\n",
    "    ]\n",
    "    \n",
    "    pvals = pvalue_comp(lambda x: binned_pmf(x, bin_tup), extremes, \n",
    "                        dx=1./(nbins/10.), bin_tup=bin_tup, by_bins=True)\n",
    "\n",
    "    res_pdata = []\n",
    "    for target in target_pvals:\n",
    "        chosen = 0\n",
    "        for i in range(len(pvals)):\n",
    "            chosen = i\n",
    "            if pvals[i][0] >= target:\n",
    "                chosen = i - 1 if i > 0 else 0\n",
    "                break\n",
    "                \n",
    "        cdata = pvals[chosen]\n",
    "        res_pdata.append(collections.OrderedDict([\n",
    "            ('pval_target', target),\n",
    "            ('pval', cdata[0]),\n",
    "            ('crit', cdata[1]),\n",
    "            ('areas', cdata[2]),\n",
    "            ('err', cdata[3]),\n",
    "        ]))\n",
    "\n",
    "    return collections.OrderedDict([\n",
    "        ('method', val['method']), \n",
    "        ('block', val['block']),\n",
    "        ('deg', val['deg']),\n",
    "        ('comb_deg', val['comb_deg']),\n",
    "        ('data_size', val['data_size']),\n",
    "        ('nsamples', len(inp_iter)),\n",
    "        ('nbins', nbins),\n",
    "        ('abs_val', abs_val),\n",
    "        ('binsize', bin_size),\n",
    "        ('minv', minv),\n",
    "        ('maxv', maxv),\n",
    "        ('extremes', extremes),\n",
    "        ('pvals', res_pdata)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#js = json.load(open('ref_1554219251.json'))\n",
    "#csv = open('ref_1554219251.csv').read()\n",
    "csv = open('ref_1557495250.csv').read()\n",
    "\n",
    "csv_data = []\n",
    "for rec in [x.strip() for x in csv.split(\"\\n\")]:\n",
    "    p = rec.split(';')\n",
    "    if len(p) < 6:\n",
    "        continue\n",
    "    cur = collections.OrderedDict([\n",
    "        ('method', p[0]), \n",
    "        ('block', int(p[1])),\n",
    "        ('deg', int(p[2])),\n",
    "        ('comb_deg', int(p[3])),\n",
    "        ('data_size', int(p[4])),\n",
    "        ('zscores', [float(x.replace(',','.')) for x in p[6:]])\n",
    "    ])\n",
    "    csv_data.append(cur)\n",
    "print(json.dumps(csv_data[0]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = csv_data\n",
    "data_filt = [x for x in data if x and len(x['zscores']) > 1000]\n",
    "data_filt.sort(key=lambda x: (x['method'], x['block'], x['deg'], x['comb_deg'], x['data_size']))\n",
    "np.random.seed(87655677)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pval_db = []\n",
    "for dix, val in enumerate(data_filt):\n",
    "    res = tabulate_pvals(val, abs_val=True)\n",
    "    pval_db.append(res)\n",
    "    print('Dump %s' % dix)\n",
    "json.dump(pval_db, open('pval_db.json', 'w+'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 200\n",
    "abs_val = True\n",
    "    \n",
    "for dix, val in enumerate(data_filt):\n",
    "    inp_iter = (val['zscores'])\n",
    "    if abs_val:\n",
    "        inp_iter = [abs(x) for x in inp_iter]\n",
    "    \n",
    "    print('%s[%s:%s:%s:%s]: %s %s' \n",
    "          % (val['method'], val['block'], val['deg'], val['comb_deg'], \n",
    "             val['data_size'], len(val['zscores']),\n",
    "             '',#dst.ppf([1-0.0001, 1-0.001, 1-0.01, 1-0.05, 1-0.10, 1-0.5, 0, 1, 0.0001, 0.001, 0.1, 0.9])\n",
    "             #dst.stats(moments='mvsk')\n",
    "            ))\n",
    "    \n",
    "    bin_tup = get_bins(inp_iter, nbins=nbins, full=True)\n",
    "    bb = get_distrib_fbins(inp_iter, bin_tup)\n",
    "    \n",
    "    bin_size = bin_tup[1]\n",
    "    minv, maxv = bin_tup[2], bin_tup[3] \n",
    "    bins = np.array([x[0] for x in bb])\n",
    "    dst = stats.rv_discrete(values=([x[0] for x in bb], [x[1] for x in bb]))\n",
    "    print(stats.rv_discrete)\n",
    "    \n",
    "    x=np.array([bins[0], bins[1], bins[6]])\n",
    "    print(dst.pmf(x))\n",
    "    print(dst._pmf(x))\n",
    "    \n",
    "    # Tabulate pvalues\n",
    "    build_integrator(bin_tup)\n",
    "    extremes = [\n",
    "        [minv, 1],\n",
    "        [0, -1],\n",
    "        [0, +1],\n",
    "        [maxv, -1]\n",
    "    ] if not abs_val else [\n",
    "        [minv, 1],\n",
    "        [maxv, -1]\n",
    "    ]\n",
    "    \n",
    "    pvals = pvalue_comp(lambda x: binned_pmf(x, bin_tup), extremes, \n",
    "                        dx=1./(nbins/10.), bin_tup=bin_tup, by_bins=True)\n",
    "    \n",
    "    n_sample = 100\n",
    "    rvs = dst.rvs(size=n_sample)\n",
    "    f, l = np.histogram(rvs, bins=bins)\n",
    "    f = np.append(f, [0])\n",
    "    probs = np.array([x[1] for x in bb])\n",
    "    #print(bins, len(bins))\n",
    "    #print(probs, len(probs))\n",
    "    #print(f, len(f))\n",
    "    #sfreq = np.vstack([np.array([x[0] for x in bb]), f, probs*n_sample]).T\n",
    "    #print(sfreq)\n",
    "    \n",
    "    print('%s[%s:%s:%s:%s]: %s %s' \n",
    "          % (val['method'], val['block'], val['deg'], val['comb_deg'], \n",
    "             val['data_size'], len(val['zscores']),\n",
    "             dst.ppf([1-0.0001, 1-0.001, 1-0.01, 1-0.05, 1-0.10, 1-0.5, 0, 1, 0.0001, 0.001, 0.1, 0.9])\n",
    "             #dst.stats(moments='mvsk')\n",
    "            ))\n",
    "    \n",
    "    x = np.linspace(min(bins),max(bins),1000)\n",
    "    plt.plot(x, dst.cdf(x))\n",
    "    plt.show()\n",
    "    \n",
    "    cdf_dev = derivative(dst.cdf, x, dx=0.5)\n",
    "    plt.plot(x,cdf_dev)\n",
    "    \n",
    "    sec_x = pvals[40]  # 49\n",
    "    print('Plotting area under: ', sec_x)\n",
    "    for ix in range(len(sec_x[1])):\n",
    "        section = np.arange(sec_x[1][ix][0], sec_x[1][ix][1], 1/20.)\n",
    "        plt.fill_between(section, derivative(dst.cdf, section, dx=0.5))\n",
    "    plt.show()\n",
    "    \n",
    "    #for pv in pvals:\n",
    "    #    sec_x = pv\n",
    "    #    for ix in range(len(sec_x[1])):\n",
    "    #        section = np.arange(sec_x[1][ix][0], sec_x[1][ix][1], 1/20.)\n",
    "    #        plt.fill_between(section, derivative(dst.cdf, section, dx=0.5))\n",
    "    #    plt.show()\n",
    "    \n",
    "    x = np.linspace(0,100,10000)\n",
    "    plt.plot(x,dst.ppf(x))\n",
    "    plt.show()\n",
    "    \n",
    "    x = np.linspace(minv,maxv,10000)\n",
    "    plt.plot(bins, dst._pmf(bins))\n",
    "    plt.show()\n",
    "    \n",
    "    x = np.linspace(minv,maxv,10000)\n",
    "    plt.plot(x, [binned_pmf(y, bin_tup) for y in x])\n",
    "    for ix in range(len(sec_x[1])):\n",
    "        section = np.linspace(sec_x[1][ix][0], sec_x[1][ix][1], 10000) #np.arange(sec_x[1][ix][0], sec_x[1][ix][1], 1/20.)\n",
    "        plt.fill_between(section, [binned_pmf(y, bin_tup)+0.0005 for y in section])\n",
    "    plt.show()\n",
    "    \n",
    "    # Idea: pvalue function = pms of the distribution. \n",
    "    # If test returns z-score with p=0 then we reject the hypothesis as we didnt get such zscore\n",
    "    # If test returns with p=0.3 we dont reject as we have our alpha set somehow...\n",
    "    # Problem: number of bins. If too many, we have small probabilities -> some alphas not reachable.\n",
    "    #if dix > 3:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(7)\n",
    "#np.zeros(np.shape(0.5),'d')\n",
    "#print(dst.ppf([1-0.01, 1-0.05, 1-0.10, 0.5, 0.6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pvalues\n",
    "def compute_pvals(dset):\n",
    "    zs = sorted()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a4_dims = (2*11.7, 8.27)\n",
    "fig, ax = pyplot.subplots(figsize=a4_dims)\n",
    "zs = data_filt[1]['zscores']\n",
    "\n",
    "for  i in range(1):\n",
    "    zs = [x for x in data_filt[i]['zscores']]\n",
    "    print(len(zs))\n",
    "    sns.distplot(a=zs, ax=ax, hist=True, norm_hist=False, bins='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pvalues\n",
    " - pvalue = probability (in the null hypothesis distribution) to be observed as a value equal to or more extreme than the value observed\n",
    " \n",
    "## computation \n",
    " - Derive CDF -> find 0 regions = extremes\n",
    " - Integrate from 0 regions towards region of increasing integral value. \n",
    " - Once sum of all integrations is alpha, stop. Integrated area is a critical region\n",
    " - Computation for x: integrate until the first integral boundary hits x. pvalue = sum of integrals\n",
    " - Tabulation: for each desired pvalue compute boundaries (4 values) where critical region starts. \n",
    " - pvalue(x): need to do the integration OR function table (\\forall zscores: P(zscore) > 0).\n",
    " - In our case 4 extremes, integrate: \n",
    "   - -\\inf towards 0\n",
    "   - +\\inf towards 0\n",
    "   - 0 towards +\\inf\n",
    "   - 0 towards -\\inf\n",
    "   - 10000 samples, pvalue = 0 -> 1/10000. \n",
    " - absolutize -> we have a new distribution -> 2x more datapoints, 2 tails.  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-1, 1, 1/20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = [0] * 8\n",
    "MAXV = 2\n",
    "\n",
    "def inc(counter):\n",
    "    global MAXV\n",
    "    ln = len(counter) - 1\n",
    "    while ln >= 0:\n",
    "        counter[ln] = (counter[ln] + 1) % MAXV\n",
    "        if (counter[ln] != 0):\n",
    "            return(counter)\n",
    "        ln-=1\n",
    "    raise ValueError('Overflow')\n",
    "\n",
    "    \n",
    "def dec(counter):\n",
    "    global MAXV\n",
    "    ln = len(counter) - 1\n",
    "    while ln >= 0:\n",
    "        counter[ln] = (counter[ln] - 1) % MAXV\n",
    "        if (counter[ln] != MAXV-1):\n",
    "            return counter\n",
    "        ln-=1\n",
    "    raise ValueError('Underflow')\n",
    "    \n",
    "    \n",
    "for i in range(20):\n",
    "    print(inc(counter))\n",
    "print('-'*80)\n",
    "for i in range(20):\n",
    "    print(dec(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from booltest import common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "common.generate_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "tmp_files = os.scandir('/tmp')\n",
    "for i in tmp_files:\n",
    "    print(i)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "3*3*3*10000*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
